{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch verison = 2.1.2\n",
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from functions import *\n",
    "from models.transformer import *\n",
    "from models.EGNN import *\n",
    "from data_loader_one_step_UVS import load_test_data\n",
    "from data_loader_one_step_UVS import load_train_data\n",
    "device = \"cpu\" #\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set shape :  (50000, 64, 9)\n",
      "torch.Size([49000, 1, 64, 9]) torch.Size([49000, 1, 64, 9]) torch.Size([1000, 1, 64, 9]) torch.Size([1000, 1, 64, 9])\n"
     ]
    }
   ],
   "source": [
    "# options for the model and training\n",
    "dataset_path = \"dataset\"\n",
    "result_path = \"results\"\n",
    "#Parameters\n",
    "path_outputs = \"./outputs/\"\n",
    "lead = 1\n",
    "delta_t =0.01\n",
    "\n",
    "batch_size = 1000\n",
    "lamda_reg =0.2\n",
    "wavenum_init=0 #10\n",
    "wavenum_init_ydir=0 #10\n",
    "\n",
    "save_interval = 10 # how often to save the model\n",
    "num_epochs = 5000\n",
    "learning_rate = 1e-3 # 0.00001\n",
    "\n",
    "#data load\n",
    "#(50000, 64, 9)\n",
    "x_tensor=np.load(os.path.join(dataset_path, \"input.npy\"))\n",
    "s = np.shape(x_tensor)\n",
    "print(\"train set shape : \", x_tensor.shape)\n",
    "# x_tensor = np.reshape(x_tensor, (s[0]*s[1],s[2], s[3]))\n",
    "\n",
    "d1,d2,d3 = np.shape(x_tensor)\n",
    "x_tensor_norm, mean_list_x, std_list_x = normalize_md(x_tensor)\n",
    "x_tensor_norm=np.reshape(x_tensor_norm, [d1,1,d2,d3])\n",
    "x_tensor_norm=torch.from_numpy(x_tensor_norm)\n",
    "y_tensor=np.load(os.path.join(dataset_path, \"output.npy\"))\n",
    "s = np.shape(y_tensor)\n",
    "#y_tensor = np.reshape(y_tensor, (s[0]*s[1],s[2], s[3]))\n",
    "d1,d2,d3 = np.shape(y_tensor)\n",
    "y_tensor_norm, mean_list_y, std_list_y = normalize_md(y_tensor)\n",
    "y_tensor_norm=np.reshape(y_tensor_norm, [d1,1,d2,d3]) \n",
    "y_tensor_norm=torch.from_numpy(y_tensor_norm)\n",
    "\n",
    "tr_x, te_x =  x_tensor_norm[:-1000], x_tensor_norm[-1000:]\n",
    "tr_y, te_y =  y_tensor_norm[:-1000], y_tensor_norm[-1000:]\n",
    "print(tr_x.shape, tr_y.shape, te_x.shape, te_y.shape) #[batch_size, channel, n_atom, atom_feature_size]\n",
    "# Define beta schedule\n",
    "T = 300\n",
    "betas = linear_beta_schedule(timesteps=T)\n",
    "# Pre-calculate different terms for closed form\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "psi_test_label_Tr = y_tensor_norm.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 64, 9]) torch.Size([1000, 1, 64, 9])\n",
      "t :  torch.Size([1000])\n",
      "torch.Size([1000, 1, 64, 9]) torch.Size([1000, 1, 64, 9])\n",
      "t :  torch.Size([1000])\n",
      "torch.Size([1000, 1, 64, 9]) torch.Size([1000, 1, 64, 9])\n",
      "t :  torch.Size([1000])\n",
      "torch.Size([1000, 1, 64, 9]) torch.Size([1000, 1, 64, 9])\n",
      "t :  torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "trainN=5000\n",
    "for step in range(0,trainN-batch_size,batch_size):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    indices = np.random.permutation(np.arange(start=step, stop=step+batch_size))\n",
    "    #print(indices)\n",
    "    input_batch, label_batch = tr_x[indices,:,:,:], tr_y[indices,:,:,:]\n",
    "    print(input_batch.shape, label_batch.shape)\n",
    "    t = torch.randint(0, T, (batch_size,), device=device).long()\n",
    "    print(\"t : \", t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_tensor = x_tensor[:10]\n",
    "# def normalize_md(x):\n",
    "#     #x: [5000,64,9]\n",
    "#     #x_out = np.zeros_like(x)\n",
    "#     d1,d2,d3 = np.shape(x)\n",
    "#     mean_list = [np.average(x[:,:,i]) for i in range(d3)]\n",
    "#     std_list = [np.std(x[:,:,i]) for i in range(d3)]\n",
    "#     for i in range(d3):\n",
    "#         for index_1 in range(d1):\n",
    "#             for index_2 in range(d2):\n",
    "#                  x[index_1,index_2,i] = (x[index_1,index_2,i]-mean_list[i])/(std_list[i])\n",
    "#     #print(np.amax(x), np.amin(x), mean_list, std_list)\n",
    "#     return x, mean_list, std_list\n",
    "# print(test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(x:torch.Tensor):\n",
    "    n_frames, n_atoms, n_features = x.shape\n",
    "    assert n_features == 3,  \"The last dimension should be 3\"\n",
    "\n",
    "    dist_mtx = torch.zeros((n_frames, n_atoms, n_atoms))\n",
    "    x2 = torch.sum(torch.square(x), dim=-1)\n",
    "    y2 = torch.sum(torch.square(x), dim=-1)\n",
    "    xy = torch.matmul(x, x.transpose(-1, -2))\n",
    "    dist_mtx = torch.sqrt(torch.maximum(x2[:, :, None] + y2[:, None, :] - 2 * xy, torch.tensor(1e-6)))\n",
    "\n",
    "    return dist_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape :  torch.Size([1000, 64, 3]) torch.Size([1000, 64, 6])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64000x6 and 9x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/scratch/x2895a03/research/md-diffusion/Ashesh/data_vis.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneuron.ksc.re.kr/scratch/x2895a03/research/md-diffusion/Ashesh/data_vis.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones((n_frames, n_atoms))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneuron.ksc.re.kr/scratch/x2895a03/research/md-diffusion/Ashesh/data_vis.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m mask2d \u001b[39m=\u001b[39m dist_mtx \u001b[39m<\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bneuron.ksc.re.kr/scratch/x2895a03/research/md-diffusion/Ashesh/data_vis.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m new_feat, new_coord \u001b[39m=\u001b[39m model(atom_feat\u001b[39m=\u001b[39mx_force_speed\u001b[39m.\u001b[39mfloat(),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneuron.ksc.re.kr/scratch/x2895a03/research/md-diffusion/Ashesh/data_vis.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m                             coord\u001b[39m=\u001b[39mx_coord\u001b[39m.\u001b[39mfloat(),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneuron.ksc.re.kr/scratch/x2895a03/research/md-diffusion/Ashesh/data_vis.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m                             t\u001b[39m=\u001b[39mt\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneuron.ksc.re.kr/scratch/x2895a03/research/md-diffusion/Ashesh/data_vis.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m                             adj_mat\u001b[39m=\u001b[39mmask2d,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneuron.ksc.re.kr/scratch/x2895a03/research/md-diffusion/Ashesh/data_vis.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m                             mask\u001b[39m=\u001b[39mmask,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneuron.ksc.re.kr/scratch/x2895a03/research/md-diffusion/Ashesh/data_vis.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m                             mask2d\u001b[39m=\u001b[39mmask2d )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneuron.ksc.re.kr/scratch/x2895a03/research/md-diffusion/Ashesh/data_vis.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(new_feat\u001b[39m.\u001b[39mshape, new_coord\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneuron.ksc.re.kr/scratch/x2895a03/research/md-diffusion/Ashesh/data_vis.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m out_pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([new_coord, new_feat], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/scratch/x2895a03/.conda/envs/smd/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/scratch/x2895a03/.conda/envs/smd/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/x2895a03/research/md-diffusion/Ashesh/models/EGNN.py:383\u001b[0m, in \u001b[0;36mEGNN.forward\u001b[0;34m(self, atom_feat, coord, t, adj_mat, mask, mask2d, condition, lattice)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_condition:\n\u001b[1;32m    382\u001b[0m         atom_feat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([coord, atom_feat, condition], dim \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# (batch, num_atom, 18)\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m atom_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeat_enc(atom_feat)\n\u001b[1;32m    384\u001b[0m t_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_enc(atom_feat, t)\n\u001b[1;32m    386\u001b[0m feat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mempty(atom_feat\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), atom_feat\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh_dim \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mto(atom_feat)\n",
      "File \u001b[0;32m/scratch/x2895a03/.conda/envs/smd/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/scratch/x2895a03/.conda/envs/smd/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/x2895a03/.conda/envs/smd/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mlinear(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64000x6 and 9x128)"
     ]
    }
   ],
   "source": [
    "model = EGNN(in_dim=64,\n",
    "            out_dim=6,\n",
    "            h_dim=128,\n",
    "            num_layer=3,\n",
    "            num_timesteps=300,\n",
    "            update_coord=True,\n",
    "            use_attention=True,\n",
    "            num_head=4)\n",
    "input_batch = input_batch.squeeze()\n",
    "# [1000, 64, 9]\n",
    "n_frames, n_atoms, n_features = input_batch.shape\n",
    "x_coord, x_force_speed = torch.split(input_batch, [3, 6], dim=-1)\n",
    "#print(input_batch)\n",
    "print(\"input shape : \", x_coord.shape, x_force_speed.shape)\n",
    "\n",
    "dist_mtx = calc_distance(x_coord)\n",
    "mask = torch.ones((n_frames, n_atoms))\n",
    "mask2d = dist_mtx < 1.0\n",
    "\n",
    "new_feat, new_coord = model(atom_feat=x_force_speed.float(),\n",
    "                            coord=x_coord.float(),\n",
    "                            t=t.view(-1,1),\n",
    "                            adj_mat=mask2d,\n",
    "                            mask=mask,\n",
    "                            mask2d=mask2d )\n",
    "\n",
    "print(new_feat.shape, new_coord.shape)\n",
    "out_pred = torch.cat([new_coord, new_feat], dim=-1)\n",
    "print(out_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffcsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
